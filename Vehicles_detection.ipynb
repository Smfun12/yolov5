{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vehicle detection\n",
        "\n",
        "Plan:\n",
        "- Find dataset of satellite images\n",
        "- Generate images inserting there photos of vehicles\n",
        "- Edit YOLOv5 to meet our needs\n",
        "- Train model"
      ],
      "metadata": {
        "id": "pO15E4AbjtDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Smfun12/yolov5  # clone\n",
        "%pip install -r yolov5/requirements.txt  # install\n",
        "%pip install wget"
      ],
      "metadata": {
        "id": "urgWdM4iHi-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fCA86Bpx5ftr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torchvision.io import read_video\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import wget\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(28, 202):\n",
        "  URL = \"https://storage.googleapis.com/drone_vehicle_footage_dataset_public/video_\"+ str(i) + \".zip\"\n",
        "  try:\n",
        "      response = wget.download(URL, \"/content/video_\" + str(i) + \".zip\")\n",
        "  except Exception:\n",
        "      # print('not found: ' + str(i))\n",
        "      pass"
      ],
      "metadata": {
        "id": "VXJ27kno1c1H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_files = [i for i in os.listdir('/content') if '.zip' in i]\n",
        "print(zip_files)\n",
        "for zip_file in zip_files:\n",
        "    with zipfile.ZipFile('/content/'+zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/videos'+'/video'+zip_file.split('_')[1].split('.')[0]+'/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYlnWoGQGjsC",
        "outputId": "4c44ab4a-ea1f-4f49-d94e-c1460225b8a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['video_124.zip', 'video_138.zip', 'video_177.zip', 'video_142.zip', 'video_139.zip', 'video_184.zip', 'video_92.zip', 'video_164.zip', 'video_200.zip', 'video_130.zip', 'video_182.zip', 'video_79.zip', 'video_192.zip', 'video_151.zip', 'video_161.zip', 'video_90.zip', 'video_158.zip', 'video_89.zip', 'video_48.zip', 'video_176.zip', 'video_77.zip', 'video_186.zip', 'video_153.zip', 'video_133.zip', 'video_136.zip', 'video_127.zip', 'video_150.zip', 'video_28.zip', 'video_152.zip', 'video_76.zip', 'video_157.zip', 'video_91.zip', 'video_39.zip', 'video_194.zip', 'video_160.zip', 'video_156.zip', 'video_78.zip', 'video_37.zip', 'video_159.zip', 'video_163.zip', 'video_57.zip', 'video_123.zip', 'video_155.zip', 'video_148.zip', 'video_30.zip', 'video_154.zip', 'video_93.zip', 'video_131.zip', 'video_121.zip', 'video_105.zip', 'video_180.zip', 'video_162.zip', 'video_193.zip', 'video_137.zip', 'video_106.zip', 'video_140.zip', 'video_179.zip', 'video_166.zip', 'video_40.zip', 'video_41.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_files = [zip_file for zip_file in os.listdir('/content/') if '.zip' in zip_file]\n",
        "for zip_file in zip_files:\n",
        "  os.remove('/content/' + zip_file)"
      ],
      "metadata": {
        "id": "iEfDmxjhcmIq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/dataset')"
      ],
      "metadata": {
        "id": "Tu8Bb6ITeCNR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/dataset/custom/images/train')\n",
        "os.makedirs('/content/dataset/custom/labels/train')"
      ],
      "metadata": {
        "id": "n6IXIcVqdJQI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos = os.listdir('/content/videos')\n",
        "classes = {'Vehicle': 0}\n",
        "files_amount = 0\n",
        "max_amount = 2000\n",
        "condition_break = False\n",
        "for video_folder in videos:\n",
        "    for root, dir, files in os.walk('/content/videos/'+video_folder):\n",
        "        if 'annotations.json' not in files:\n",
        "            continue\n",
        "        idx = files.index('annotations.json')\n",
        "\n",
        "        with open('/content/videos/'+video_folder+'/'+files[idx], 'r') as json_file:\n",
        "            json_file = json.load(json_file)\n",
        "        tracks = json_file[0]['tracks']\n",
        "        vehicles = [vehicle for vehicle in tracks if vehicle['label'] == 'Vehicle']\n",
        "        success_frames = []\n",
        "        points_arr = []\n",
        "        for i in vehicles:\n",
        "            for j in i['shapes']:\n",
        "                if j['points'] is not None and j['frame'] not in success_frames:\n",
        "                    success_frames.append(j['frame'])\n",
        "                    points_arr.append(j['points'])\n",
        "                    files_amount += 1\n",
        "                    if files_amount == max_amount:\n",
        "                        condition_break = True\n",
        "                        break\n",
        "            if condition_break:\n",
        "                break\n",
        "\n",
        "        video = os.listdir('/content/videos/'+video_folder+'/'+dir[0])[0]\n",
        "        vidcap = cv2.VideoCapture('/content/videos/'+video_folder+'/'+dir[0]+'/'+video)\n",
        "        success, image = vidcap.read()\n",
        "        count = 0\n",
        "        shapes = {}\n",
        "        while success:\n",
        "            if count in success_frames:\n",
        "                shapes[count] = (image.shape[1], image.shape[0])\n",
        "                cv2.imwrite(\"/content/dataset/custom/images/train/frame%d.jpg\" % count, image)  # save frame as JPEG file\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "        counter = 0\n",
        "        assert len(shapes) == len(success_frames), 'Len shapes is less that frames'\n",
        "        for points in points_arr:\n",
        "            success_frame = success_frames[counter]\n",
        "            x_center = (points[2] + points[0]) / 2\n",
        "            y_center = (points[3] + points[1]) / 2\n",
        "            width = abs(points[2] - points[0])\n",
        "            height = abs(points[3] - points[1])\n",
        "            img_width = shapes[success_frame][0]\n",
        "            img_height = shapes[success_frame][1]\n",
        "            x_center_normalized = min(1.0,x_center / img_width)\n",
        "            y_center_normalized = min(1.0, y_center / img_height)\n",
        "            width_normalized = min(1.0, width / img_width)\n",
        "            height_normalized = min(1.0,height / img_height)\n",
        "            # assert x_center_normalized < 1.0\n",
        "            # assert y_center_normalized < 1.0\n",
        "            # assert width_normalized < 1.0\n",
        "            # assert height_normalized < 1.0\n",
        "            file = open('/content/dataset/custom/labels/train/frame' + str(success_frame) + '.txt', 'w')\n",
        "            yolo_format = str(classes['Vehicle']) + \" \" + str(x_center_normalized) + \" \" + str(\n",
        "                y_center_normalized) + \" \" + str(width_normalized) + \" \" + str(height_normalized)\n",
        "            file.write(yolo_format)\n",
        "            file.close()\n",
        "            counter += 1\n",
        "    if condition_break:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "qFQM3tm2oVT7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv5s on dataset for 3 epochs\n",
        "# %cd yolov5\n",
        "!python /content/yolov5/train.py --img 640 --batch 16 --epochs 10 --data custom_dataset.yaml --weights yolov5s.pt"
      ],
      "metadata": {
        "id": "uCP4tE_X8eUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('result', 'zip', '/content/yolov5/runs')"
      ],
      "metadata": {
        "id": "AbSVzyCGg42d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1af1e711-c99a-4f56-f8de-4b32626ee308"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/result.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}